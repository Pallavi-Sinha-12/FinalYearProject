{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691a3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#When user will be detected using mobile phone his photo with the number plate and current time stamp will be recorded in\n",
    "#MongoDB Database. The records will be displayed on the website from where notification can be sent to the user for submission\n",
    "#of fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f636e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pygame\n",
    "import datetime\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047cf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE = 0.7\n",
    "SCORE_THRESHOLD = 0.7\n",
    "IOU_THRESHOLD = 0.7\n",
    "CHECK_TIME = 10\n",
    "NUMBER_PLATE = \"BR-12345\"\n",
    "alarm = \"ALARM.wav\"\n",
    "config_path = \"yolov4-tiny-obj.cfg\"\n",
    "weights = \"3000.weights\"\n",
    "labels = open(\"obj.names\").read().strip().split(\"\\n\")\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1e9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "pygame.mixer.music.load(alarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b16cf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb+srv://m001-student:m001-mongodb-basics@sandbox.akvcd.mongodb.net/My_Database?retryWrites=true&w=majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b16ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.get_database(\"My_Database\")\n",
    "records_collection = db.MobilePhoneUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99a8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(config_path, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2b0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRecords(x,y,w,h,image):\n",
    "    if x>0 and y>0:\n",
    "        cropped = image[y:y+h, x:x+w]\n",
    "        cropped = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "        cropped = Image.fromarray(cropped)\n",
    "        cropped = cropped.resize((100,100))\n",
    "        image_bytes = io.BytesIO()\n",
    "        cropped.save(image_bytes, format='JPEG')\n",
    "        base64_image = base64.b64encode(image_bytes.getvalue())\n",
    "        record = {\n",
    "                'image': base64_image,\n",
    "                 'number_plate': NUMBER_PLATE,\n",
    "                'time': datetime.datetime.now()\n",
    "            }\n",
    "        records_collection.insert_one(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "179a70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    time = datetime.datetime.now()\n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        h,w = image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(image, 1/255.0, (416,416), swapRB = True, crop = False)\n",
    "        net.setInput(blob)\n",
    "        ln = net.getLayerNames()\n",
    "        ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        layer_outputs = net.forward(ln)\n",
    "        boxes, confidences, class_ids = [], [], []\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence>CONFIDENCE:\n",
    "                    box = detection[:4]*np.array([w,h,w,h])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    boxes.append([x,y,int(width), int(height)])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "        font_scale = 1\n",
    "        thickness = 1\n",
    "        \n",
    "        if len(idxs)>0:\n",
    "            for i in idxs.flatten():\n",
    "                x,y = boxes[i][0], boxes[i][1]\n",
    "                w,h = boxes[i][2], boxes[i][3]\n",
    "                if (labels[class_ids[i]]==\"talking\" or labels[class_ids[i]]==\"texting\"):\n",
    "                    pygame.mixer.music.play()\n",
    "                    delta = datetime.datetime.now()- time\n",
    "                    if delta.seconds >= CHECK_TIME:\n",
    "                        saveRecords(x,y,w,h,image)\n",
    "                        time = datetime.datetime.now()\n",
    "                color = [int(c) for c in colors[class_ids[i]]]\n",
    "                cv2.rectangle(image, (x,y), (x+w, y+h), color = color, thickness= thickness)\n",
    "                text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "                (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "                text_offset_x = x\n",
    "                text_offset_y = y - 5\n",
    "                box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "                overlay = image.copy()\n",
    "                cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "                image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "                cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "        cv2.imshow(\"output\", image)\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10e049f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6143615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
